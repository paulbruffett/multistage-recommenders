{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5d37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run main function\n",
    "path = \"/mnt/c/mldata/aliccp\"\n",
    "log_path = \"/mnt/c/mldata/aliccp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914eabae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41999771\n",
      "9477639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_218/1915021112.py:28: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_y'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_train = pd.merge(cust_agg, df_train, on=['user_id', 'user_id'], how='left')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473399\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int64, name='integer_lookup_5_input'), name='integer_lookup_5_input', description=\"created by layer 'integer_lookup_5_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/tmp/ipykernel_218/1915021112.py\", line 101, in compute_loss\n        return self.task(user_embeddings, positive_item_embeddings)\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileo38aqctf.py\", line 159, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"/tmp/__autograph_generated_fileo38aqctf.py\", line 155, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"/tmp/__autograph_generated_fileo38aqctf.py\", line 154, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"/tmp/__autograph_generated_filevtqt02ea.py\", line 50, in tf__update_state\n        (top_k_predictions, retrieved_ids) = ag__.converted_call(ag__.ld(self)._candidates, (ag__.ld(query_embeddings),), dict(k=ag__.converted_call(ag__.ld(max), (ag__.ld(self)._ks,), None, fscope)), fscope)\n    File \"/tmp/__autograph_generated_filen507280_.py\", line 163, in tf__call\n        results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n    File \"/tmp/__autograph_generated_filen507280_.py\", line 98, in top_k\n        joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n\n    ValueError: Exception encountered when calling layer 'retrieval_1' (type Retrieval).\n    \n    in user code:\n    \n        File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py\", line 136, in update_state  *\n            top_k_predictions, retrieved_ids = self._candidates(\n        File \"/home/paul/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_filen507280_.py\", line 163, in tf__call\n            results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n        File \"/tmp/__autograph_generated_filen507280_.py\", line 98, in top_k\n            joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n    \n        ValueError: Exception encountered when calling layer 'streaming_1' (type Streaming).\n        \n        in user code:\n        \n            File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\", line 454, in top_k  *\n                joined_scores = tf.concat([state_scores, x_scores], axis=1)\n        \n            ValueError: Shape must be rank 2 but is rank 3 for '{{node concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](args_0, args_2, concat/axis)' with input shapes: [?,0], [?,?,?], [].\n        \n        \n        Call arguments received by layer 'streaming_1' (type Streaming):\n          • queries=tf.Tensor(shape=(None, 64), dtype=float32)\n          • k=100\n    \n    \n    Call arguments received by layer 'retrieval_1' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m cached_train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m100_000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m8192\u001b[39m)\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    108\u001b[0m cached_test \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m4096\u001b[39m)\u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m--> 110\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m512\u001b[39m), return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m index \u001b[38;5;241m=\u001b[39m tfrs\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mfactorized_top_k\u001b[38;5;241m.\u001b[39mBruteForce(model\u001b[38;5;241m.\u001b[39muser_model,k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1lpmpyx6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 68\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "Cell \u001b[0;32mIn[4], line 101\u001b[0m, in \u001b[0;36mRetrievalModel.compute_loss\u001b[0;34m(self, features, training)\u001b[0m\n\u001b[1;32m     98\u001b[0m positive_item_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_model(features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# The task computes the loss and the metrics.\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_item_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileo38aqctf.py:159\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_5\u001b[39m():\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_9\u001b[39m():\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileo38aqctf.py:155\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     metric \u001b[38;5;241m=\u001b[39m itr_1\n\u001b[1;32m    154\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(update_ops)\u001b[38;5;241m.\u001b[39mappend, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(metric)\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(query_embeddings), ag__\u001b[38;5;241m.\u001b[39mld(candidate_embeddings)[:ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(query_embeddings),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]]), \u001b[38;5;28mdict\u001b[39m(true_candidate_ids\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(candidate_ids)), fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m--> 155\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_factorized_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileo38aqctf.py:154\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5.<locals>.loop_body_1\u001b[0;34m(itr_1)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_body_1\u001b[39m(itr_1):\n\u001b[1;32m    153\u001b[0m     metric \u001b[38;5;241m=\u001b[39m itr_1\n\u001b[0;32m--> 154\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(update_ops)\u001b[38;5;241m.\u001b[39mappend, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrue_candidate_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevtqt02ea.py:50\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001b[0;34m(self, query_embeddings, true_candidate_embeddings, true_candidate_ids, sample_weight)\u001b[0m\n\u001b[1;32m     48\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mand_(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(true_candidate_ids) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_candidates\u001b[38;5;241m.\u001b[39mis_exact, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope))), if_body, else_body, get_state, set_state, (), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     49\u001b[0m positive_scores \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_sum, (ag__\u001b[38;5;241m.\u001b[39mld(query_embeddings) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(true_candidate_embeddings),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 50\u001b[0m (top_k_predictions, retrieved_ids) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m update_ops \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_4\u001b[39m():\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filen507280_.py:163\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, queries, k)\u001b[0m\n\u001b[1;32m    161\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mzeros, ((ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(queries),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), fscope), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mzeros, ((ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(queries),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(index_dtype)), fscope))\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(_wrap_batch_too_small_error)(ag__\u001b[38;5;241m.\u001b[39mld(k)):\n\u001b[0;32m--> 163\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_parallel_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filen507280_.py:98\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.top_k\u001b[0;34m(state, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m (state_scores, state_indices) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(state)\n\u001b[1;32m     97\u001b[0m (x_scores, x_indices) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(x)\n\u001b[0;32m---> 98\u001b[0m joined_scores \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m joined_indices \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mld(state_indices), ag__\u001b[38;5;241m.\u001b[39mld(x_indices)],), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope_2)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_3\u001b[39m():\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/tmp/ipykernel_218/1915021112.py\", line 101, in compute_loss\n        return self.task(user_embeddings, positive_item_embeddings)\n    File \"/home/paul/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileo38aqctf.py\", line 159, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"/tmp/__autograph_generated_fileo38aqctf.py\", line 155, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"/tmp/__autograph_generated_fileo38aqctf.py\", line 154, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"/tmp/__autograph_generated_filevtqt02ea.py\", line 50, in tf__update_state\n        (top_k_predictions, retrieved_ids) = ag__.converted_call(ag__.ld(self)._candidates, (ag__.ld(query_embeddings),), dict(k=ag__.converted_call(ag__.ld(max), (ag__.ld(self)._ks,), None, fscope)), fscope)\n    File \"/tmp/__autograph_generated_filen507280_.py\", line 163, in tf__call\n        results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n    File \"/tmp/__autograph_generated_filen507280_.py\", line 98, in top_k\n        joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n\n    ValueError: Exception encountered when calling layer 'retrieval_1' (type Retrieval).\n    \n    in user code:\n    \n        File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py\", line 136, in update_state  *\n            top_k_predictions, retrieved_ids = self._candidates(\n        File \"/home/paul/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_filen507280_.py\", line 163, in tf__call\n            results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n        File \"/tmp/__autograph_generated_filen507280_.py\", line 98, in top_k\n            joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n    \n        ValueError: Exception encountered when calling layer 'streaming_1' (type Streaming).\n        \n        in user code:\n        \n            File \"/home/paul/.local/lib/python3.10/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\", line 454, in top_k  *\n                joined_scores = tf.concat([state_scores, x_scores], axis=1)\n        \n            ValueError: Shape must be rank 2 but is rank 3 for '{{node concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](args_0, args_2, concat/axis)' with input shapes: [?,0], [?,?,?], [].\n        \n        \n        Call arguments received by layer 'streaming_1' (type Streaming):\n          • queries=tf.Tensor(shape=(None, 64), dtype=float32)\n          • k=100\n    \n    \n    Call arguments received by layer 'retrieval_1' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import argparse\n",
    "\n",
    "from typing import Dict, Text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import tensorflow_recommenders as tfrs\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "\n",
    "df_train = pd.read_parquet(path+'/train_processed/')\n",
    "print(len(df_train))\n",
    "\n",
    "#filter out long tail products and reduce size of dataset\n",
    "df_train['counter'] = 1\n",
    "df_agg = df_train[['item_id','counter']].groupby('item_id').count()\n",
    "df_agg = df_agg.sort_values(\"counter\",ascending=False)[:10000]\n",
    "df_train = pd.merge(df_agg, df_train, on=['item_id', 'item_id'], how='left')\n",
    "print(len(df_train))\n",
    "df_train['counter'] = 1\n",
    "cust_agg = df_train[['user_id','counter']].groupby('user_id').count()\n",
    "cust_agg = cust_agg.sort_values(\"counter\",ascending=False)[:8000]\n",
    "df_train = pd.merge(cust_agg, df_train, on=['user_id', 'user_id'], how='left')\n",
    "print(len(df_train))\n",
    "\n",
    "train = df_train[df_train['click']==1][['item_id','user_id']]\n",
    "features = ['item_id','user_id']\n",
    "for i in features:\n",
    "    train[i] = pd.to_numeric(train[i], errors='coerce',downcast=\"integer\")\n",
    "train= train.dropna()\n",
    "\n",
    "items = train['item_id'].unique()\n",
    "items = tf.convert_to_tensor(items, dtype=tf.int64)\n",
    "\n",
    "train = tf.convert_to_tensor(train, dtype=tf.int64)\n",
    "\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices(train)\n",
    "\n",
    "interactions = train.map(lambda x: {\n",
    "    \"item_id\": x[0],\n",
    "    \"user_id\": x[1],\n",
    "})\n",
    "\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(items)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "split = round(len(shuffled)*.8)\n",
    "\n",
    "train = shuffled.take(split)\n",
    "test = shuffled.skip(split).take(len(shuffled)-split)\n",
    "\n",
    "item_ds = item_ds.batch(1_000)\n",
    "user_ids = interactions.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_items = np.unique(np.concatenate(list(item_ds)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "embedding_dimension = 64\n",
    "mlflow.log_param(\"embedding_dimension\", embedding_dimension)\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=unique_user_ids, mask_token=None),\n",
    "# We add an additional embedding to account for unknown tokens.\n",
    "tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "item_model = tf.keras.Sequential([\n",
    "tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=unique_items, mask_token=None),\n",
    "tf.keras.layers.Embedding(len(unique_items) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=item_ds.batch(128).map(item_model))\n",
    "\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)\n",
    "\n",
    "class RetrievalModel(tfrs.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.item_model: tf.keras.Model = item_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_item_embeddings = self.item_model(features['item_id'])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_item_embeddings)\n",
    "\n",
    "model = RetrievalModel(user_model, item_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=4)\n",
    "\n",
    "\n",
    "model.evaluate(test.batch(512), return_dict=True)\n",
    "\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model,k = 50)\n",
    "\n",
    "index.index_from_dataset(tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model.item_model))))\n",
    "\n",
    "_, titles = index(tf.constant([42]))\n",
    "print(titles)\n",
    "tf.saved_model.save(index, \"index\")\n",
    "mlflow.log_artifacts(\"index\", \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004745f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
