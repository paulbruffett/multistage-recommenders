{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f28ace0-18fa-4d48-b546-984d8bb64288",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q scann\n",
    "!pip install -q azure-storage-blob\n",
    "!pip install -q tensorboard\n",
    "!pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf00956-5a1a-4dac-9496-08e98e03d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 15:31:49.467917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 15:31:50.872084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 15:31:50.872161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 15:31:50.872167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635020d1-e45d-4fe8-a819-2c78baacbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76fe6449-0534-46cf-8247-b596ade6ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41999771\n",
      "9477639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12568/425168829.py:17: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_y'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_train = pd.merge(cust_agg, df_train, on=['user_id', 'user_id'], how='left')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# run main function\n",
    "path = \"/mnt/c/mldata/aliccp\"\n",
    "log_path = \"/mnt/c/mldata/aliccp\"\n",
    "\n",
    "df_train = pd.read_parquet(path+'/train_processed/')\n",
    "print(len(df_train))\n",
    "\n",
    "#filter out long tail products and reduce size of dataset\n",
    "df_train['counter'] = 1\n",
    "df_agg = df_train[['item_id','counter']].groupby('item_id').count()\n",
    "df_agg = df_agg.sort_values(\"counter\",ascending=False)[:10000]\n",
    "df_train = pd.merge(df_agg, df_train, on=['item_id', 'item_id'], how='left')\n",
    "print(len(df_train))\n",
    "df_train['counter'] = 1\n",
    "cust_agg = df_train[['user_id','counter']].groupby('user_id').count()\n",
    "cust_agg = cust_agg.sort_values(\"counter\",ascending=False)[:8000]\n",
    "df_train = pd.merge(cust_agg, df_train, on=['user_id', 'user_id'], how='left')\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "143a700a-e89a-4bd3-b569-38932b056b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train[df_train['click']==1][['item_id','user_id']]\n",
    "features = ['item_id','user_id']\n",
    "for i in features:\n",
    "    train[i] = pd.to_numeric(train[i], errors='coerce',downcast=\"integer\")\n",
    "train= train.dropna()\n",
    "\n",
    "items = train['item_id'].unique()\n",
    "items = tf.convert_to_tensor(items, dtype=tf.int64)\n",
    "\n",
    "train = tf.convert_to_tensor(train, dtype=tf.int64)\n",
    "\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices(train)\n",
    "\n",
    "ratings = train.map(lambda x: {\n",
    "    \"item_id\": x[0],\n",
    "    \"user_id\": x[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b420df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = tf.data.Dataset.from_tensor_slices(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e89757f-c23d-4df6-82c8-553ec520f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "split = round(len(shuffled)*.8)\n",
    "\n",
    "train = shuffled.take(split)\n",
    "test = shuffled.skip(split).take(len(shuffled)-split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "679926b3-eda3-4d65-ad4b-46e5a5526c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3967652, 3970819, 3971286, 3973275, 3973379, 3973932, 3976967,\n",
       "       3977999, 3979755, 3985259])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0d9c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9130"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2159a039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7421"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9192c5ce-eb67-4dd8-8f80-b4030b4a425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b48c9ae-b580-4275-8800-fa65c5307ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.IntegerLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2b55ff3-da84-4969-b24b-a62d06466019",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.IntegerLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7a450d4-a25b-414b-b4f9-23265ebea816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 7s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.0849e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0012 - factorized_top_k/top_50_categorical_accuracy: 0.0056 - factorized_top_k/top_100_categorical_accuracy: 0.0104 - loss: 58387.6048 - regularization_loss: 0.0000e+00 - total_loss: 58387.6048\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0051 - factorized_top_k/top_5_categorical_accuracy: 0.0844 - factorized_top_k/top_10_categorical_accuracy: 0.1651 - factorized_top_k/top_50_categorical_accuracy: 0.4443 - factorized_top_k/top_100_categorical_accuracy: 0.5877 - loss: 57984.3978 - regularization_loss: 0.0000e+00 - total_loss: 57984.3978\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0177 - factorized_top_k/top_5_categorical_accuracy: 0.1935 - factorized_top_k/top_10_categorical_accuracy: 0.3263 - factorized_top_k/top_50_categorical_accuracy: 0.7016 - factorized_top_k/top_100_categorical_accuracy: 0.8345 - loss: 56170.4980 - regularization_loss: 0.0000e+00 - total_loss: 56170.4980\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0251 - factorized_top_k/top_5_categorical_accuracy: 0.2858 - factorized_top_k/top_10_categorical_accuracy: 0.4522 - factorized_top_k/top_50_categorical_accuracy: 0.8348 - factorized_top_k/top_100_categorical_accuracy: 0.9232 - loss: 50821.8138 - regularization_loss: 0.0000e+00 - total_loss: 50821.8138\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 7s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0301 - factorized_top_k/top_5_categorical_accuracy: 0.3724 - factorized_top_k/top_10_categorical_accuracy: 0.5813 - factorized_top_k/top_50_categorical_accuracy: 0.9288 - factorized_top_k/top_100_categorical_accuracy: 0.9693 - loss: 42209.9128 - regularization_loss: 0.0000e+00 - total_loss: 42209.9128\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 7s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0352 - factorized_top_k/top_5_categorical_accuracy: 0.4355 - factorized_top_k/top_10_categorical_accuracy: 0.7050 - factorized_top_k/top_50_categorical_accuracy: 0.9773 - factorized_top_k/top_100_categorical_accuracy: 0.9904 - loss: 33559.2161 - regularization_loss: 0.0000e+00 - total_loss: 33559.2161\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0383 - factorized_top_k/top_5_categorical_accuracy: 0.4701 - factorized_top_k/top_10_categorical_accuracy: 0.7905 - factorized_top_k/top_50_categorical_accuracy: 0.9943 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 26865.2113 - regularization_loss: 0.0000e+00 - total_loss: 26865.2113\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0357 - factorized_top_k/top_5_categorical_accuracy: 0.4933 - factorized_top_k/top_10_categorical_accuracy: 0.8291 - factorized_top_k/top_50_categorical_accuracy: 0.9985 - factorized_top_k/top_100_categorical_accuracy: 0.9997 - loss: 22276.0667 - regularization_loss: 0.0000e+00 - total_loss: 22276.0667\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0398 - factorized_top_k/top_5_categorical_accuracy: 0.5188 - factorized_top_k/top_10_categorical_accuracy: 0.8408 - factorized_top_k/top_50_categorical_accuracy: 0.9999 - factorized_top_k/top_100_categorical_accuracy: 0.9999 - loss: 19341.6865 - regularization_loss: 0.0000e+00 - total_loss: 19341.6865\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0438 - factorized_top_k/top_5_categorical_accuracy: 0.5396 - factorized_top_k/top_10_categorical_accuracy: 0.8474 - factorized_top_k/top_50_categorical_accuracy: 0.9999 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 17539.8496 - regularization_loss: 0.0000e+00 - total_loss: 17539.8496\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0522 - factorized_top_k/top_5_categorical_accuracy: 0.5520 - factorized_top_k/top_10_categorical_accuracy: 0.8491 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 16449.2677 - regularization_loss: 0.0000e+00 - total_loss: 16449.2677\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0558 - factorized_top_k/top_5_categorical_accuracy: 0.5567 - factorized_top_k/top_10_categorical_accuracy: 0.8507 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 15786.0018 - regularization_loss: 0.0000e+00 - total_loss: 15786.0018\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0600 - factorized_top_k/top_5_categorical_accuracy: 0.5589 - factorized_top_k/top_10_categorical_accuracy: 0.8521 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 15366.6336 - regularization_loss: 0.0000e+00 - total_loss: 15366.6336\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0639 - factorized_top_k/top_5_categorical_accuracy: 0.5644 - factorized_top_k/top_10_categorical_accuracy: 0.8530 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 15082.1323 - regularization_loss: 0.0000e+00 - total_loss: 15082.1323\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 6s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0660 - factorized_top_k/top_5_categorical_accuracy: 0.5676 - factorized_top_k/top_10_categorical_accuracy: 0.8547 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 14873.5726 - regularization_loss: 0.0000e+00 - total_loss: 14873.5726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8645309a80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")\n",
    "\n",
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_movie_embeddings = self.movie_model(features[\"item_id\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)\n",
    "\n",
    "\n",
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f5e07f3-67db-40fb-9b77-4ea0ffd144fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 387ms/step - factorized_top_k/top_1_categorical_accuracy: 2.2126e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0028 - factorized_top_k/top_10_categorical_accuracy: 0.0063 - factorized_top_k/top_50_categorical_accuracy: 0.0223 - factorized_top_k/top_100_categorical_accuracy: 0.0394 - loss: 28410.3608 - regularization_loss: 0.0000e+00 - total_loss: 28410.3608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0002212634135503322,\n",
       " 0.002765792654827237,\n",
       " 0.006306007504463196,\n",
       " 0.022347604855895042,\n",
       " 0.039384886622428894,\n",
       " 8205.4541015625,\n",
       " 0,\n",
       " 8205.4541015625]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666bbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
