{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e56dc09-be7c-4509-8914-d04f2a129a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorboard\n",
    "!pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76710d79-6951-4d6d-842e-baced9dbd46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 18:18:24.257908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 18:18:25.017858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-11 18:18:25.017934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-11 18:18:25.017944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41999771\n",
      "9477639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2243/1411737331.py:28: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_y'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_train = pd.merge(cust_agg, df_train, on=['user_id', 'user_id'], how='left')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473399\n"
     ]
    }
   ],
   "source": [
    "# Setup. Import libraries and load dataframes for Movielens data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "\n",
    "# run main function\n",
    "path = \"/storage/aliccp/\"\n",
    "log_path = \"/storage/aliccp/\"\n",
    "\n",
    "df_train = pd.read_parquet(path+'/train_processed/')\n",
    "\n",
    "\n",
    "print(len(df_train))\n",
    "\n",
    "#filter out long tail products and reduce size of dataset\n",
    "df_train['counter'] = 1\n",
    "df_agg = df_train[['item_id','counter']].groupby('item_id').count()\n",
    "df_agg = df_agg.sort_values(\"counter\",ascending=False)[:10000]\n",
    "df_train = pd.merge(df_agg, df_train, on=['item_id', 'item_id'], how='left')\n",
    "print(len(df_train))\n",
    "df_train['counter'] = 1\n",
    "cust_agg = df_train[['user_id','counter']].groupby('user_id').count()\n",
    "cust_agg = cust_agg.sort_values(\"counter\",ascending=False)[:8000]\n",
    "df_train = pd.merge(cust_agg, df_train, on=['user_id', 'user_id'], how='left')\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6233ee8c-69a2-4c82-8fd4-0891a4161098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2243/257137575.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = pd.to_numeric(train[i], errors='coerce',downcast=\"integer\")\n"
     ]
    }
   ],
   "source": [
    "train = df_train[['item_id','user_id','user_categories', 'user_item_categories',\n",
    "                                       'user_intentions','user_item_intentions','user_shops','user_item_brands','click']]\n",
    "\n",
    "features = ['item_id','user_id','user_categories']\n",
    "for i in features:\n",
    "    train[i] = pd.to_numeric(train[i], errors='coerce',downcast=\"integer\")\n",
    "train= train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75fd3324-33dc-4ef3-8b8d-2de7a52c35c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "________________________________________________________________________________________\n",
      " Layer (type)                Output Shape       Param #   Connected to                  \n",
      "========================================================================================\n",
      " user_id (InputLayer)        [(None, 1)]        0         []                            \n",
      "                                                                                        \n",
      " item_id (InputLayer)        [(None, 1)]        0         []                            \n",
      "                                                                                        \n",
      " user_categories (InputLayer  [(None, 1)]       0         []                            \n",
      " )                                                                                      \n",
      "                                                                                        \n",
      " user_embedding (Embedding)  (None, 1, 32)      47148800  ['user_id[0][0]']             \n",
      "                                                                                        \n",
      " item_embedding (Embedding)  (None, 1, 32)      47148800  ['item_id[0][0]']             \n",
      "                                                                                        \n",
      " user_categories_embedding (  (None, 1, 32)     47148800  ['user_categories[0][0]']     \n",
      " Embedding)                                                                             \n",
      "                                                                                        \n",
      " concatenate_1 (Concatenate)  (None, 1, 96)     0         ['user_embedding[0][0]',      \n",
      "                                                           'item_embedding[0][0]',      \n",
      "                                                           'user_categories_embedding[0]\n",
      "                                                          [0]']                         \n",
      "                                                                                        \n",
      " flatten_1 (Flatten)         (None, 96)         0         ['concatenate_1[0][0]']       \n",
      "                                                                                        \n",
      " dense_2 (Dense)             (None, 192)        18624     ['flatten_1[0][0]']           \n",
      "                                                                                        \n",
      " dense_3 (Dense)             (None, 20)         3860      ['dense_2[0][0]']             \n",
      "                                                                                        \n",
      " prediction (Dense)          (None, 1)          21        ['dense_3[0][0]']             \n",
      "                                                                                        \n",
      "========================================================================================\n",
      "Total params: 141,468,905\n",
      "Trainable params: 141,468,905\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_units = (192,20)\n",
    "embedding_size = 32\n",
    "\n",
    "# Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "item_id_input = keras.Input(shape=(1,), name='item_id')\n",
    "user_categories_input = keras.Input(shape=(1,), name='user_categories')\n",
    "user_embedding = keras.layers.Embedding(len(train['user_id'])+1, embedding_size, \n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "item_embedding = keras.layers.Embedding(len(train['item_id'])+1, embedding_size, \n",
    "                                        input_length=1, name='item_embedding')(item_id_input)\n",
    "user_categories = keras.layers.Embedding(len(train['user_categories'])+1, embedding_size, \n",
    "                                        input_length=1, name='user_categories_embedding')(user_categories_input)\n",
    "# Concatenate the embeddings (and remove the useless extra dimension)\n",
    "concatenated = keras.layers.Concatenate()([user_embedding, item_embedding,user_categories])\n",
    "out = keras.layers.Flatten()(concatenated)\n",
    "\n",
    "# Add one or more hidden layers\n",
    "for n_hidden in hidden_units:\n",
    "    out = keras.layers.Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "# A single output: our predicted rating\n",
    "out = keras.layers.Dense(1, activation='sigmoid', name='prediction')(out)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, item_id_input, user_categories_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.summary(line_length=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f698bc-c1b1-45e9-a98d-e3dcc8fe369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(0.01),\n",
    "    loss='MAE',\n",
    "    metrics=[tf.keras.metrics.BinaryCrossentropy(\"BCE\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea27dff2-df9b-4692-98eb-5e9b1072f430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "280/280 [==============================] - 41s 144ms/step - loss: 0.0348 - BCE: 2.4035 - val_loss: 0.0316 - val_BCE: 1.9224\n",
      "Epoch 2/20\n",
      "280/280 [==============================] - 12s 42ms/step - loss: 0.0306 - BCE: 2.5751 - val_loss: 0.0316 - val_BCE: 1.9218\n",
      "Epoch 3/20\n",
      "280/280 [==============================] - 9s 33ms/step - loss: 0.0306 - BCE: 2.5745 - val_loss: 0.0316 - val_BCE: 1.9216\n",
      "Epoch 4/20\n",
      "280/280 [==============================] - 8s 27ms/step - loss: 0.0306 - BCE: 2.5743 - val_loss: 0.0316 - val_BCE: 1.9214\n",
      "Epoch 5/20\n",
      "280/280 [==============================] - 8s 28ms/step - loss: 0.0306 - BCE: 2.5741 - val_loss: 0.0316 - val_BCE: 1.9213\n",
      "Epoch 6/20\n",
      "280/280 [==============================] - 7s 25ms/step - loss: 0.0306 - BCE: 2.5739 - val_loss: 0.0316 - val_BCE: 1.9213\n",
      "Epoch 7/20\n",
      "280/280 [==============================] - 7s 24ms/step - loss: 0.0306 - BCE: 2.5738 - val_loss: 0.0316 - val_BCE: 1.9212\n",
      "Epoch 8/20\n",
      "280/280 [==============================] - 7s 26ms/step - loss: 0.0306 - BCE: 2.5737 - val_loss: 0.0316 - val_BCE: 1.9211\n",
      "Epoch 9/20\n",
      "280/280 [==============================] - 7s 24ms/step - loss: 0.0306 - BCE: 2.5737 - val_loss: 0.0316 - val_BCE: 1.9211\n",
      "Epoch 10/20\n",
      "280/280 [==============================] - 7s 26ms/step - loss: 0.0306 - BCE: 2.5736 - val_loss: 0.0316 - val_BCE: 1.9210\n",
      "Epoch 11/20\n",
      "280/280 [==============================] - 7s 24ms/step - loss: 0.0306 - BCE: 2.5736 - val_loss: 0.0316 - val_BCE: 1.9210\n",
      "Epoch 12/20\n",
      "280/280 [==============================] - 7s 26ms/step - loss: 0.0306 - BCE: 2.5735 - val_loss: 0.0316 - val_BCE: 1.9210\n",
      "Epoch 13/20\n",
      "280/280 [==============================] - 7s 25ms/step - loss: 0.0306 - BCE: 2.5735 - val_loss: 0.0316 - val_BCE: 1.9209\n",
      "Epoch 14/20\n",
      "280/280 [==============================] - 7s 23ms/step - loss: 0.0306 - BCE: 2.5734 - val_loss: 0.0316 - val_BCE: 1.9209\n",
      "Epoch 15/20\n",
      "280/280 [==============================] - 6s 23ms/step - loss: 0.0306 - BCE: 2.5734 - val_loss: 0.0316 - val_BCE: 1.9209\n",
      "Epoch 16/20\n",
      "280/280 [==============================] - 6s 23ms/step - loss: 0.0306 - BCE: 2.5734 - val_loss: 0.0316 - val_BCE: 1.9209\n",
      "Epoch 17/20\n",
      "280/280 [==============================] - 7s 25ms/step - loss: 0.0306 - BCE: 2.5734 - val_loss: 0.0316 - val_BCE: 1.9209\n",
      "Epoch 18/20\n",
      "280/280 [==============================] - 7s 25ms/step - loss: 0.0306 - BCE: 2.5734 - val_loss: 0.0316 - val_BCE: 1.9208\n",
      "Epoch 19/20\n",
      "280/280 [==============================] - 7s 24ms/step - loss: 0.0306 - BCE: 2.5733 - val_loss: 0.0316 - val_BCE: 1.9208\n",
      "Epoch 20/20\n",
      "280/280 [==============================] - 7s 24ms/step - loss: 0.0306 - BCE: 2.5733 - val_loss: 0.0316 - val_BCE: 1.9208\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train['user_id'], train['item_id'], train['user_categories']],\n",
    "    train['click'],\n",
    "    batch_size=5000,\n",
    "    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9cda8-cb7c-4331-b6e1-52f109953beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
